{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c75217f",
   "metadata": {},
   "source": [
    "# Persiapan Data dan Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5fe97ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "278ce0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (40000, 32, 32, 3), (40000,)\n",
      "Validation data: (10000, 32, 32, 3), (10000,)\n",
      "Test data: (10000, 32, 32, 3), (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train_full = x_train_full.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "split_idx = 40000\n",
    "x_train = x_train_full[:split_idx]\n",
    "y_train = y_train_full[:split_idx]\n",
    "x_val = x_train_full[split_idx:]\n",
    "y_val = y_train_full[split_idx:]\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "print(f\"Training data: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation data: {x_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test data: {x_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e81f11",
   "metadata": {},
   "source": [
    "# Implementasi Model CNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ce7de34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], \n",
    "                     kernel_sizes=[3, 3], pooling_type='max'):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(shape=(32, 32, 3)))\n",
    "    \n",
    "    for i in range(conv_layers):\n",
    "        filters = filters_per_layer[i] if i < len(filters_per_layer) else filters_per_layer[-1]\n",
    "        kernel_size = kernel_sizes[i] if i < len(kernel_sizes) else kernel_sizes[-1]\n",
    "        \n",
    "        model.add(layers.Conv2D(filters, kernel_size, activation='relu', padding='same'))\n",
    "        \n",
    "        if pooling_type == 'max':\n",
    "            model.add(layers.MaxPooling2D(2, 2))\n",
    "        elif pooling_type == 'avg':\n",
    "            model.add(layers.AveragePooling2D(2, 2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6f50c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, epochs=2):\n",
    "  model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=epochs,\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    "  )\n",
    "\n",
    "  model.save(f'models/{model_name}.h5')\n",
    "\n",
    "  with open(f'histories/{model_name}_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "  \n",
    "  return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1622d1",
   "metadata": {},
   "source": [
    "# Eksperimen Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "843354fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 21ms/step - accuracy: 0.2361 - loss: 2.0307 - val_accuracy: 0.4756 - val_loss: 1.5427\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 17ms/step - accuracy: 0.3579 - loss: 1.6852 - val_accuracy: 0.4956 - val_loss: 1.4451\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.3134 - loss: 1.8554 - val_accuracy: 0.5326 - val_loss: 1.3111\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.5023 - loss: 1.3788 - val_accuracy: 0.5992 - val_loss: 1.1314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.2969 - loss: 1.8897 - val_accuracy: 0.5483 - val_loss: 1.2481\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 16ms/step - accuracy: 0.5247 - loss: 1.3250 - val_accuracy: 0.6210 - val_loss: 1.0710\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Jumlah Layer Konvolusi\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('histories', exist_ok=True)\n",
    "\n",
    "model_1_layer = create_cnn_model(conv_layers=1, filters_per_layer=[32])\n",
    "model_1_layer, history_1_layer = train_model(model_1_layer, 'model_1_conv_layer')\n",
    "\n",
    "model_2_layer = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64])\n",
    "model_2_layer, history_2_layer = train_model(model_2_layer, 'model_2_conv_layers')\n",
    "\n",
    "model_3_layer = create_cnn_model(conv_layers=3, filters_per_layer=[32, 64, 128])\n",
    "model_3_layer, history_3_layer = train_model(model_3_layer ,'model_3_conv_layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "281fd547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 9ms/step - accuracy: 0.3100 - loss: 1.8757 - val_accuracy: 0.5096 - val_loss: 1.3667\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.5012 - loss: 1.3843 - val_accuracy: 0.5978 - val_loss: 1.1517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 18ms/step - accuracy: 0.3071 - loss: 1.8645 - val_accuracy: 0.5350 - val_loss: 1.3173\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.5032 - loss: 1.3660 - val_accuracy: 0.5919 - val_loss: 1.1387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 36ms/step - accuracy: 0.3233 - loss: 1.8296 - val_accuracy: 0.5639 - val_loss: 1.2570\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 37ms/step - accuracy: 0.5260 - loss: 1.3281 - val_accuracy: 0.6156 - val_loss: 1.1481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Jumlah Filter per Layer\n",
    "model_low_filters = create_cnn_model(conv_layers=2, filters_per_layer=[16, 32])\n",
    "model_low_filters, history_low_layer = train_model(model_low_filters, 'model_low_filters')\n",
    "\n",
    "model_med_filters = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64])\n",
    "model_med_filters, history_med_layer = train_model(model_med_filters, 'model_med_filters')\n",
    "\n",
    "model_high_filters = create_cnn_model(conv_layers=2, filters_per_layer=[64, 128])\n",
    "model_high_filters, history_high_layer = train_model(model_high_filters, 'model_high_filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3f90f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - accuracy: 0.3217 - loss: 1.8271 - val_accuracy: 0.5478 - val_loss: 1.2705\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 18ms/step - accuracy: 0.5076 - loss: 1.3690 - val_accuracy: 0.5966 - val_loss: 1.1283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 22ms/step - accuracy: 0.3092 - loss: 1.8705 - val_accuracy: 0.5236 - val_loss: 1.3296\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 21ms/step - accuracy: 0.4953 - loss: 1.3963 - val_accuracy: 0.5839 - val_loss: 1.1769\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 25ms/step - accuracy: 0.2856 - loss: 1.9302 - val_accuracy: 0.4828 - val_loss: 1.4571\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m33s\u001b[0m 26ms/step - accuracy: 0.4739 - loss: 1.4761 - val_accuracy: 0.5504 - val_loss: 1.2655\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Ukuran Filter\n",
    "model_small_kernel = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], kernel_sizes=[3, 3])\n",
    "model_small_kernel, history_small_kernel = train_model(model_small_kernel, 'model_small_kernel')\n",
    "\n",
    "model_med_kernel = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], kernel_sizes=[5, 5])\n",
    "model_med_kernel, history_med_kernel = train_model(model_med_kernel, 'model_med_kernel')\n",
    "\n",
    "model_large_kernel = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], kernel_sizes=[7, 7])\n",
    "model_large_kernel, history_large_kernel = train_model(model_large_kernel, 'model_large_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "adc97361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 20ms/step - accuracy: 0.3141 - loss: 1.8619 - val_accuracy: 0.5286 - val_loss: 1.3242\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m26s\u001b[0m 20ms/step - accuracy: 0.5081 - loss: 1.3701 - val_accuracy: 0.5896 - val_loss: 1.1648\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m27s\u001b[0m 19ms/step - accuracy: 0.3171 - loss: 1.8513 - val_accuracy: 0.5226 - val_loss: 1.3594\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m24s\u001b[0m 19ms/step - accuracy: 0.4934 - loss: 1.4008 - val_accuracy: 0.5728 - val_loss: 1.2134\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Jenis Pooling\n",
    "model_max_pool = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], pooling_type='max')\n",
    "model_max_pool, history_max_pool = train_model(model_max_pool, 'model_max_pooling')\n",
    "\n",
    "model_avg_pool = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], pooling_type='avg')\n",
    "model_avg_pool, history_avg_pool = train_model(model_avg_pool, 'model_avg_pooling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e0010",
   "metadata": {},
   "source": [
    "# Evaluasi dan Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3982199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name):\n",
    "  y_pred_proba = model.predict(x_test)\n",
    "  y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "  f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "  print(f\"Model: {model_name}\")\n",
    "  print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "  print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "  print(\"-\" * 40)\n",
    "\n",
    "  return test_acc, f1_macro\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5cb67825",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(histories, labels, title):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history, label in zip(histories, labels):\n",
    "        plt.plot(history['loss'], label=f'{label} - Training')\n",
    "        plt.plot(history['val_loss'], label=f'{label} - Validation', linestyle='--')\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history, label in zip(histories, labels):\n",
    "        plt.plot(history['accuracy'], label=f'{label} - Training')\n",
    "        plt.plot(history['val_accuracy'], label=f'{label} - Validation', linestyle='--')\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634aa2b0",
   "metadata": {},
   "source": [
    "# Implementasi Forward Propagation From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23c5b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNNFromScratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446c15f",
   "metadata": {},
   "source": [
    "# Testing dan Validasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17ed5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_propagation(keras_model, model_name):\n",
    "    \"\"\"\n",
    "    Test implementasi forward propagation from scratch\n",
    "    \"\"\"\n",
    "    # Load model dari file\n",
    "    keras_model = keras.models.load_model(f'models/{model_name}.h5')\n",
    "    \n",
    "    # Buat model from scratch\n",
    "    scratch_model = CNNFromScratch(keras_model)\n",
    "    \n",
    "    # Test dengan subset data test (untuk efisiensi)\n",
    "    test_samples = x_test[:100]\n",
    "    \n",
    "    # Prediksi dengan Keras\n",
    "    keras_pred = keras_model.predict(test_samples)\n",
    "    keras_pred_classes = np.argmax(keras_pred, axis=1)\n",
    "    \n",
    "    # Prediksi dengan implementasi from scratch\n",
    "    scratch_pred = scratch_model.predict(test_samples)\n",
    "    scratch_pred_classes = np.argmax(scratch_pred, axis=1)\n",
    "    \n",
    "    # Bandingkan hasil\n",
    "    accuracy_match = np.mean(keras_pred_classes == scratch_pred_classes)\n",
    "    \n",
    "    # Hitung F1-score untuk kedua implementasi\n",
    "    y_true = y_test[:100]\n",
    "    keras_f1 = f1_score(y_true, keras_pred_classes, average='macro')\n",
    "    scratch_f1 = f1_score(y_true, scratch_pred_classes, average='macro')\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Prediction Match Accuracy: {accuracy_match:.4f}\")\n",
    "    print(f\"Keras F1-Score: {keras_f1:.4f}\")\n",
    "    print(f\"From Scratch F1-Score: {scratch_f1:.4f}\")\n",
    "    print(f\"Difference in F1-Score: {abs(keras_f1 - scratch_f1):.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return accuracy_match, keras_f1, scratch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92840700",
   "metadata": {},
   "source": [
    "# Langkah Eksekusi Lengkap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7b715754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading and preprocessing CIFAR-10 data...\n",
      "2. Training models with different configurations...\n",
      "3. Evaluating all models...\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1 Conv Layer\n",
      "Test Accuracy: 0.5015\n",
      "Macro F1-Score: 0.4974\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 2 Conv Layers\n",
      "Test Accuracy: 0.5999\n",
      "Macro F1-Score: 0.5983\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 3 Conv Layers\n",
      "Test Accuracy: 0.6239\n",
      "Macro F1-Score: 0.6126\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Low Filters\n",
      "Test Accuracy: 0.6007\n",
      "Macro F1-Score: 0.5898\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Medium Filters\n",
      "Test Accuracy: 0.5957\n",
      "Macro F1-Score: 0.5860\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: High Filters\n",
      "Test Accuracy: 0.6088\n",
      "Macro F1-Score: 0.6094\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Small Kernel\n",
      "Test Accuracy: 0.5953\n",
      "Macro F1-Score: 0.5870\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Medium Kernel\n",
      "Test Accuracy: 0.5877\n",
      "Macro F1-Score: 0.5797\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 9ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Large Kernel\n",
      "Test Accuracy: 0.5537\n",
      "Macro F1-Score: 0.5504\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Max Pooling\n",
      "Test Accuracy: 0.5909\n",
      "Macro F1-Score: 0.5896\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Average Pooling\n",
      "Test Accuracy: 0.5670\n",
      "Macro F1-Score: 0.5584\n",
      "----------------------------------------\n",
      "4. Plotting comparisons...\n",
      "5. Testing forward propagation implementation...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_1_conv_layer\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.4800\n",
      "From Scratch F1-Score: 0.4800\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "WARNING:tensorflow:5 out of the last 318 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017F5E3091C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 318 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017F5E3091C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 69ms/stepWARNING:tensorflow:6 out of the last 321 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017F5E3091C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 321 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017F5E3091C0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 28ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_2_conv_layers\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6169\n",
      "From Scratch F1-Score: 0.6169\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_3_conv_layers\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6743\n",
      "From Scratch F1-Score: 0.6743\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 31ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_low_filters\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.5968\n",
      "From Scratch F1-Score: 0.5968\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_med_filters\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6092\n",
      "From Scratch F1-Score: 0.6092\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_high_filters\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6254\n",
      "From Scratch F1-Score: 0.6254\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_small_kernel\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6034\n",
      "From Scratch F1-Score: 0.6034\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_med_kernel\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6724\n",
      "From Scratch F1-Score: 0.6724\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_large_kernel\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6731\n",
      "From Scratch F1-Score: 0.6731\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_max_pooling\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6417\n",
      "From Scratch F1-Score: 0.6417\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "Model: model_avg_pooling\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.5543\n",
      "From Scratch F1-Score: 0.5543\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "6. Saving results...\n",
      "All experiments completed!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. Persiapan data\n",
    "    print(\"1. Loading and preprocessing CIFAR-10 data...\")\n",
    "    # (kode preprocessing di atas)\n",
    "    \n",
    "    # 2. Training semua variasi model\n",
    "    print(\"2. Training models with different configurations...\")\n",
    "    # (kode training di atas)\n",
    "    \n",
    "    # 3. Evaluasi semua model\n",
    "    print(\"3. Evaluating all models...\")\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluasi untuk setiap eksperimen\n",
    "    model_configs = [\n",
    "        ('model_1_conv_layer', '1 Conv Layer'),\n",
    "        ('model_2_conv_layers', '2 Conv Layers'),\n",
    "        ('model_3_conv_layers', '3 Conv Layers'),\n",
    "        ('model_low_filters', 'Low Filters'),\n",
    "        ('model_med_filters', 'Medium Filters'),\n",
    "        ('model_high_filters', 'High Filters'),\n",
    "        ('model_small_kernel', 'Small Kernel'),\n",
    "        ('model_med_kernel', 'Medium Kernel'),\n",
    "        ('model_large_kernel', 'Large Kernel'),\n",
    "        ('model_max_pooling', 'Max Pooling'),\n",
    "        ('model_avg_pooling', 'Average Pooling')\n",
    "    ]\n",
    "    \n",
    "    for model_name, display_name in model_configs:\n",
    "        model = keras.models.load_model(f'models/{model_name}.h5')\n",
    "        test_acc, f1_macro = evaluate_model(model, display_name)\n",
    "        results[model_name] = {'accuracy': test_acc, 'f1_score': f1_macro}\n",
    "    \n",
    "    # 4. Plot perbandingan\n",
    "    print(\"4. Plotting comparisons...\")\n",
    "    # (kode plotting di atas)\n",
    "    \n",
    "    # 5. Test forward propagation\n",
    "    print(\"5. Testing forward propagation implementation...\")\n",
    "    for model_name, display_name in model_configs:\n",
    "        test_forward_propagation(keras.models.load_model(f'models/{model_name}.h5'), model_name)\n",
    "    \n",
    "    # 6. Simpan hasil\n",
    "    print(\"6. Saving results...\")\n",
    "    with open('experiment_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    print(\"All experiments completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
