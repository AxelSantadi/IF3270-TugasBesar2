{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3c75217f",
   "metadata": {},
   "source": [
    "# Persiapan Data dan Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5fe97ba6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "278ce0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data: (40000, 32, 32, 3), (40000,)\n",
      "Validation data: (10000, 32, 32, 3), (10000,)\n",
      "Test data: (10000, 32, 32, 3), (10000,)\n"
     ]
    }
   ],
   "source": [
    "(x_train_full, y_train_full), (x_test, y_test) = keras.datasets.cifar10.load_data()\n",
    "\n",
    "x_train_full = x_train_full.astype('float32') / 255.0\n",
    "x_test = x_test.astype('float32') / 255.0\n",
    "\n",
    "split_idx = 40000\n",
    "x_train = x_train_full[:split_idx]\n",
    "y_train = y_train_full[:split_idx]\n",
    "x_val = x_train_full[split_idx:]\n",
    "y_val = y_train_full[split_idx:]\n",
    "\n",
    "y_train = y_train.flatten()\n",
    "y_val = y_val.flatten()\n",
    "y_test = y_test.flatten()\n",
    "\n",
    "print(f\"Training data: {x_train.shape}, {y_train.shape}\")\n",
    "print(f\"Validation data: {x_val.shape}, {y_val.shape}\")\n",
    "print(f\"Test data: {x_test.shape}, {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e81f11",
   "metadata": {},
   "source": [
    "# Implementasi Model CNN Baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce7de34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], \n",
    "                     kernel_sizes=[3, 3], pooling_type='max'):\n",
    "    model = keras.Sequential()\n",
    "    \n",
    "    model.add(layers.Input(shape=(32, 32, 3)))\n",
    "    \n",
    "    for i in range(conv_layers):\n",
    "        filters = filters_per_layer[i] if i < len(filters_per_layer) else filters_per_layer[-1]\n",
    "        kernel_size = kernel_sizes[i] if i < len(kernel_sizes) else kernel_sizes[-1]\n",
    "        \n",
    "        model.add(layers.Conv2D(filters, kernel_size, activation='relu', padding='same'))\n",
    "        \n",
    "        if pooling_type == 'max':\n",
    "            model.add(layers.MaxPooling2D(2, 2))\n",
    "        elif pooling_type == 'avg':\n",
    "            model.add(layers.AveragePooling2D(2, 2))\n",
    "    \n",
    "    model.add(layers.Flatten())\n",
    "    \n",
    "    model.add(layers.Dense(128, activation='relu'))\n",
    "    model.add(layers.Dropout(0.5))\n",
    "    model.add(layers.Dense(10, activation='softmax'))\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f50c9f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_training_history(histories, labels, title, experiment_name=\"cnn_experiment\"): # Tambahkan experiment_name\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    plt.subplot(1, 2, 1)\n",
    "    for history_dict, label in zip(histories, labels): # Asumsi histories adalah list of dicts\n",
    "        plt.plot(history_dict['loss'], label=f'{label} - Training')\n",
    "        plt.plot(history_dict['val_loss'], label=f'{label} - Validation', linestyle='--')\n",
    "    plt.title(f'{title} - Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for history_dict, label in zip(histories, labels): # Asumsi histories adalah list of dicts\n",
    "        plt.plot(history_dict['accuracy'], label=f'{label} - Training')\n",
    "        plt.plot(history_dict['val_accuracy'], label=f'{label} - Validation', linestyle='--')\n",
    "    plt.title(f'{title} - Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Bagian untuk menyimpan plot\n",
    "    plot_filename = f\"results/cnn_plots/{experiment_name}_{title.replace(' ', '_')}_history.png\"\n",
    "    os.makedirs(os.path.dirname(plot_filename), exist_ok=True) # Membuat direktori jika belum ada\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Saved plot to {plot_filename}\")\n",
    "    plt.show() # Anda masih bisa menampilkannya jika mau, atau plt.close() jika tidak ingin ditampilkan langsung\n",
    "    \n",
    "def plot_and_save_single_history(history_obj, model_name_str, experiment_label=\"cnn_experiment\"):\n",
    "    history_data = history_obj.history # history_obj adalah objek History dari Keras\n",
    "    plt.figure(figsize=(12, 4))\n",
    "\n",
    "    # Plot Loss\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(history_data['loss'], label='Training Loss')\n",
    "    plt.plot(history_data['val_loss'], label='Validation Loss')\n",
    "    plt.title(f'Loss - {model_name_str}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(history_data['accuracy'], label='Training Accuracy')\n",
    "    plt.plot(history_data['val_accuracy'], label='Validation Accuracy')\n",
    "    plt.title(f'Accuracy - {model_name_str}')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "\n",
    "    plot_filename = f\"results/cnn_plots/{experiment_label}_{model_name_str.replace(' ', '_').replace('/', '_')}_history.png\"\n",
    "    os.makedirs(os.path.dirname(plot_filename), exist_ok=True)\n",
    "    plt.savefig(plot_filename)\n",
    "    print(f\"Saved plot to {plot_filename}\")\n",
    "    plt.close() # Tutup plot agar tidak menumpuk jika dijalankan dalam loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ab617795",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, model_name, epochs=2): # model_name di sini adalah nama file, bukan display name\n",
    "  model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    "  )\n",
    "\n",
    "  history = model.fit(\n",
    "    x_train, y_train,\n",
    "    batch_size=32,\n",
    "    epochs=epochs, # Gunakan epochs dari parameter\n",
    "    validation_data=(x_val, y_val),\n",
    "    verbose=1\n",
    "  )\n",
    "\n",
    "  # Membuat direktori jika belum ada (dipindahkan ke awal skrip utama atau di sini per model)\n",
    "  os.makedirs('models', exist_ok=True)\n",
    "  os.makedirs('histories', exist_ok=True)\n",
    "  os.makedirs('results/cnn_plots', exist_ok=True) # Pastikan direktori plot ada\n",
    "\n",
    "  model.save(f'models/{model_name}.h5') # model_name adalah nama file\n",
    "\n",
    "  with open(f'histories/{model_name}_history.pkl', 'wb') as f:\n",
    "    pickle.dump(history.history, f)\n",
    "\n",
    "  plot_and_save_single_history(history, model_name, \"cnn_experiment\") \n",
    "\n",
    "  return model, history"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af1622d1",
   "metadata": {},
   "source": [
    "# Eksperimen Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "843354fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 16ms/step - accuracy: 0.3009 - loss: 1.8948 - val_accuracy: 0.5208 - val_loss: 1.3825\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m22s\u001b[0m 18ms/step - accuracy: 0.4516 - loss: 1.4992 - val_accuracy: 0.5379 - val_loss: 1.3115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_1_conv_layer_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 12ms/step - accuracy: 0.3045 - loss: 1.8738 - val_accuracy: 0.5363 - val_loss: 1.3156\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.4870 - loss: 1.4040 - val_accuracy: 0.5725 - val_loss: 1.2324\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_2_conv_layers_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 15ms/step - accuracy: 0.2815 - loss: 1.9204 - val_accuracy: 0.5178 - val_loss: 1.3321\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 13ms/step - accuracy: 0.5174 - loss: 1.3503 - val_accuracy: 0.6032 - val_loss: 1.1265\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_3_conv_layers_history.png\n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Jumlah Layer Konvolusi\n",
    "os.makedirs('models', exist_ok=True)\n",
    "os.makedirs('histories', exist_ok=True)\n",
    "\n",
    "model_1_layer = create_cnn_model(conv_layers=1, filters_per_layer=[32])\n",
    "model_1_layer, history_1_layer = train_model(model_1_layer, 'model_1_conv_layer')\n",
    "\n",
    "model_2_layer = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64])\n",
    "model_2_layer, history_2_layer = train_model(model_2_layer, 'model_2_conv_layers')\n",
    "\n",
    "model_3_layer = create_cnn_model(conv_layers=3, filters_per_layer=[32, 64, 128])\n",
    "model_3_layer, history_3_layer = train_model(model_3_layer ,'model_3_conv_layers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "281fd547",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 7ms/step - accuracy: 0.2828 - loss: 1.9350 - val_accuracy: 0.4969 - val_loss: 1.3947\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 7ms/step - accuracy: 0.4668 - loss: 1.4702 - val_accuracy: 0.5606 - val_loss: 1.2751\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_low_filters_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.2914 - loss: 1.9007 - val_accuracy: 0.5209 - val_loss: 1.3613\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.4933 - loss: 1.3925 - val_accuracy: 0.5951 - val_loss: 1.1559\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_med_filters_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m36s\u001b[0m 28ms/step - accuracy: 0.3102 - loss: 1.8526 - val_accuracy: 0.5234 - val_loss: 1.3207\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 28ms/step - accuracy: 0.5080 - loss: 1.3661 - val_accuracy: 0.6044 - val_loss: 1.1365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_high_filters_history.png\n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Jumlah Filter per Layer\n",
    "model_low_filters = create_cnn_model(conv_layers=2, filters_per_layer=[16, 32])\n",
    "model_low_filters, history_low_layer = train_model(model_low_filters, 'model_low_filters')\n",
    "\n",
    "model_med_filters = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64])\n",
    "model_med_filters, history_med_layer = train_model(model_med_filters, 'model_med_filters')\n",
    "\n",
    "model_high_filters = create_cnn_model(conv_layers=2, filters_per_layer=[64, 128])\n",
    "model_high_filters, history_high_layer = train_model(model_high_filters, 'model_high_filters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3f90f1c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.3282 - loss: 1.8240 - val_accuracy: 0.5659 - val_loss: 1.2331\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.5395 - loss: 1.2959 - val_accuracy: 0.6171 - val_loss: 1.0868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_small_kernel_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 15ms/step - accuracy: 0.2904 - loss: 1.9081 - val_accuracy: 0.5237 - val_loss: 1.3163\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 14ms/step - accuracy: 0.4997 - loss: 1.3945 - val_accuracy: 0.5806 - val_loss: 1.1726\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_med_kernel_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 29ms/step - accuracy: 0.2816 - loss: 1.9352 - val_accuracy: 0.4861 - val_loss: 1.4407\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m23s\u001b[0m 19ms/step - accuracy: 0.4689 - loss: 1.4703 - val_accuracy: 0.5504 - val_loss: 1.2609\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_large_kernel_history.png\n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Ukuran Filter\n",
    "model_small_kernel = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], kernel_sizes=[3, 3])\n",
    "model_small_kernel, history_small_kernel = train_model(model_small_kernel, 'model_small_kernel')\n",
    "\n",
    "model_med_kernel = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], kernel_sizes=[5, 5])\n",
    "model_med_kernel, history_med_kernel = train_model(model_med_kernel, 'model_med_kernel')\n",
    "\n",
    "model_large_kernel = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], kernel_sizes=[7, 7])\n",
    "model_large_kernel, history_large_kernel = train_model(model_large_kernel, 'model_large_kernel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "adc97361",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.3011 - loss: 1.8899 - val_accuracy: 0.5427 - val_loss: 1.3078\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 12ms/step - accuracy: 0.4939 - loss: 1.3960 - val_accuracy: 0.5835 - val_loss: 1.1906\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_max_pooling_history.png\n",
      "Epoch 1/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 11ms/step - accuracy: 0.3082 - loss: 1.8735 - val_accuracy: 0.5084 - val_loss: 1.3864\n",
      "Epoch 2/2\n",
      "\u001b[1m1250/1250\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 11ms/step - accuracy: 0.4730 - loss: 1.4645 - val_accuracy: 0.5560 - val_loss: 1.2389\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved plot to results/cnn_plots/cnn_experiment_model_avg_pooling_history.png\n"
     ]
    }
   ],
   "source": [
    "# Pengaruh Jenis Pooling\n",
    "model_max_pool = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], pooling_type='max')\n",
    "model_max_pool, history_max_pool = train_model(model_max_pool, 'model_max_pooling')\n",
    "\n",
    "model_avg_pool = create_cnn_model(conv_layers=2, filters_per_layer=[32, 64], pooling_type='avg')\n",
    "model_avg_pool, history_avg_pool = train_model(model_avg_pool, 'model_avg_pooling')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e73e0010",
   "metadata": {},
   "source": [
    "# Evaluasi dan Analisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3982199a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, model_name):\n",
    "  y_pred_proba = model.predict(x_test)\n",
    "  y_pred = np.argmax(y_pred_proba, axis=1)\n",
    "\n",
    "  f1_macro = f1_score(y_test, y_pred, average='macro')\n",
    "\n",
    "  test_loss, test_acc = model.evaluate(x_test, y_test, verbose=0)\n",
    "\n",
    "  print(f\"Model: {model_name}\")\n",
    "  print(f\"Test Accuracy: {test_acc:.4f}\")\n",
    "  print(f\"Macro F1-Score: {f1_macro:.4f}\")\n",
    "  print(\"-\" * 40)\n",
    "\n",
    "  return test_acc, f1_macro\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "634aa2b0",
   "metadata": {},
   "source": [
    "# Implementasi Forward Propagation From Scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23c5b8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model import CNNFromScratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a446c15f",
   "metadata": {},
   "source": [
    "# Testing dan Validasi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17ed5100",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_forward_propagation(keras_model, model_name):\n",
    "    \"\"\"\n",
    "    Test implementasi forward propagation from scratch\n",
    "    \"\"\"\n",
    "    # Load model dari file\n",
    "    keras_model = keras.models.load_model(f'models/{model_name}.h5')\n",
    "    \n",
    "    # Buat model from scratch\n",
    "    scratch_model = CNNFromScratch(keras_model)\n",
    "    \n",
    "    # Test dengan subset data test (untuk efisiensi)\n",
    "    test_samples = x_test[:100]\n",
    "    \n",
    "    # Prediksi dengan Keras\n",
    "    keras_pred = keras_model.predict(test_samples)\n",
    "    keras_pred_classes = np.argmax(keras_pred, axis=1)\n",
    "    \n",
    "    # Prediksi dengan implementasi from scratch\n",
    "    scratch_pred = scratch_model.predict(test_samples)\n",
    "    scratch_pred_classes = np.argmax(scratch_pred, axis=1)\n",
    "    \n",
    "    # Bandingkan hasil\n",
    "    accuracy_match = np.mean(keras_pred_classes == scratch_pred_classes)\n",
    "    \n",
    "    # Hitung F1-score untuk kedua implementasi\n",
    "    y_true = y_test[:100]\n",
    "    keras_f1 = f1_score(y_true, keras_pred_classes, average='macro')\n",
    "    scratch_f1 = f1_score(y_true, scratch_pred_classes, average='macro')\n",
    "    \n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Prediction Match Accuracy: {accuracy_match:.4f}\")\n",
    "    print(f\"Keras F1-Score: {keras_f1:.4f}\")\n",
    "    print(f\"From Scratch F1-Score: {scratch_f1:.4f}\")\n",
    "    print(f\"Difference in F1-Score: {abs(keras_f1 - scratch_f1):.6f}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    return accuracy_match, keras_f1, scratch_f1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92840700",
   "metadata": {},
   "source": [
    "# Langkah Eksekusi Lengkap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7b715754",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Loading and preprocessing CIFAR-10 data...\n",
      "2. Training models with different configurations...\n",
      "3. Evaluating all models...\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 1 Conv Layer\n",
      "Test Accuracy: 0.5403\n",
      "Macro F1-Score: 0.5293\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 2 Conv Layers\n",
      "Test Accuracy: 0.5777\n",
      "Macro F1-Score: 0.5669\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 3 Conv Layers\n",
      "Test Accuracy: 0.6077\n",
      "Macro F1-Score: 0.6048\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Low Filters\n",
      "Test Accuracy: 0.5650\n",
      "Macro F1-Score: 0.5631\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Medium Filters\n",
      "Test Accuracy: 0.5982\n",
      "Macro F1-Score: 0.5926\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 7ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: High Filters\n",
      "Test Accuracy: 0.5979\n",
      "Macro F1-Score: 0.5931\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Small Kernel\n",
      "Test Accuracy: 0.6205\n",
      "Macro F1-Score: 0.6140\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Medium Kernel\n",
      "Test Accuracy: 0.5784\n",
      "Macro F1-Score: 0.5663\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Large Kernel\n",
      "Test Accuracy: 0.5518\n",
      "Macro F1-Score: 0.5508\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Max Pooling\n",
      "Test Accuracy: 0.5881\n",
      "Macro F1-Score: 0.5850\n",
      "----------------------------------------\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 5ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: Average Pooling\n",
      "Test Accuracy: 0.5630\n",
      "Macro F1-Score: 0.5545\n",
      "----------------------------------------\n",
      "4. Plotting comparisons...\n",
      "5. Testing forward propagation implementation...\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_1_conv_layer\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6216\n",
      "From Scratch F1-Score: 0.6216\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "WARNING:tensorflow:5 out of the last 318 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025299FFCF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 318 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025299FFCF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/4\u001b[0m \u001b[32m━━━━━\u001b[0m\u001b[37m━━━━━━━━━━━━━━━\u001b[0m \u001b[1m0s\u001b[0m 49ms/stepWARNING:tensorflow:6 out of the last 321 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025299FFCF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 321 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000025299FFCF40> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_2_conv_layers\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6278\n",
      "From Scratch F1-Score: 0.6278\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_3_conv_layers\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6752\n",
      "From Scratch F1-Score: 0.6752\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_low_filters\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6063\n",
      "From Scratch F1-Score: 0.6063\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_med_filters\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6337\n",
      "From Scratch F1-Score: 0.6337\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_high_filters\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6413\n",
      "From Scratch F1-Score: 0.6413\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_small_kernel\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6410\n",
      "From Scratch F1-Score: 0.6410\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 22ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_med_kernel\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6592\n",
      "From Scratch F1-Score: 0.6592\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_large_kernel\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.5986\n",
      "From Scratch F1-Score: 0.5986\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: model_max_pooling\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.5933\n",
      "From Scratch F1-Score: 0.5933\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "Model: model_avg_pooling\n",
      "Prediction Match Accuracy: 1.0000\n",
      "Keras F1-Score: 0.6462\n",
      "From Scratch F1-Score: 0.6462\n",
      "Difference in F1-Score: 0.000000\n",
      "--------------------------------------------------\n",
      "6. Saving results...\n",
      "All experiments completed!\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # 1. Persiapan data\n",
    "    print(\"1. Loading and preprocessing CIFAR-10 data...\")\n",
    "    # (kode preprocessing di atas)\n",
    "    \n",
    "    # 2. Training semua variasi model\n",
    "    print(\"2. Training models with different configurations...\")\n",
    "    # (kode training di atas)\n",
    "    \n",
    "    # 3. Evaluasi semua model\n",
    "    print(\"3. Evaluating all models...\")\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluasi untuk setiap eksperimen\n",
    "    model_configs = [\n",
    "        ('model_1_conv_layer', '1 Conv Layer'),\n",
    "        ('model_2_conv_layers', '2 Conv Layers'),\n",
    "        ('model_3_conv_layers', '3 Conv Layers'),\n",
    "        ('model_low_filters', 'Low Filters'),\n",
    "        ('model_med_filters', 'Medium Filters'),\n",
    "        ('model_high_filters', 'High Filters'),\n",
    "        ('model_small_kernel', 'Small Kernel'),\n",
    "        ('model_med_kernel', 'Medium Kernel'),\n",
    "        ('model_large_kernel', 'Large Kernel'),\n",
    "        ('model_max_pooling', 'Max Pooling'),\n",
    "        ('model_avg_pooling', 'Average Pooling')\n",
    "    ]\n",
    "    \n",
    "    for model_name, display_name in model_configs:\n",
    "        model = keras.models.load_model(f'models/{model_name}.h5')\n",
    "        test_acc, f1_macro = evaluate_model(model, display_name)\n",
    "        results[model_name] = {'accuracy': test_acc, 'f1_score': f1_macro}\n",
    "    \n",
    "    # 4. Plot perbandingan\n",
    "    print(\"4. Plotting comparisons...\")\n",
    "    # (kode plotting di atas)\n",
    "    \n",
    "    # 5. Test forward propagation\n",
    "    print(\"5. Testing forward propagation implementation...\")\n",
    "    for model_name, display_name in model_configs:\n",
    "        test_forward_propagation(keras.models.load_model(f'models/{model_name}.h5'), model_name)\n",
    "    \n",
    "    # 6. Simpan hasil\n",
    "    print(\"6. Saving results...\")\n",
    "    with open('experiment_results.pkl', 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    \n",
    "    print(\"All experiments completed!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
